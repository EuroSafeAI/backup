1:"$Sreact.fragment"
2:I[70119,["/_next/static/chunks/744355e03808d4c7.js","/_next/static/chunks/00e9ab075e5969cf.js"],"default"]
3:I[22016,["/_next/static/chunks/744355e03808d4c7.js","/_next/static/chunks/00e9ab075e5969cf.js"],""]
c:I[85437,["/_next/static/chunks/744355e03808d4c7.js","/_next/static/chunks/00e9ab075e5969cf.js"],"Image"]
d:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/d2be314c3ece3fbe.js"],"OutletBoundary"]
e:"$Sreact.suspense"
0:{"buildId":"MaNt7SMe7Hlw2xotvMfUs","rsc":["$","$1","c",{"children":[["$","div",null,{"className":"min-h-screen flex flex-col bg-white","children":[["$","$L2",null,{}],["$","main",null,{"className":"flex-1","children":[["$","section",null,{"className":"bg-primary-700 py-14 lg:py-20","children":["$","div",null,{"className":"max-w-4xl mx-auto px-6","children":[["$","$L3",null,{"href":"/research","className":"inline-flex items-center gap-1.5 text-primary-200 hover:text-white text-sm mb-6 transition-colors","children":[["$","svg",null,{"className":"w-4 h-4","fill":"none","stroke":"currentColor","viewBox":"0 0 24 24","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M15 19l-7-7 7-7"}]}],"Back to Research"]}],["$","div",null,{"className":"flex flex-wrap items-center gap-2 mb-4","children":[["$","span",null,{"className":"text-xs font-semibold px-3 py-1 rounded-full bg-white/20 text-white","children":"Democracy Defense"}],"$undefined"]}],["$","h1",null,{"className":"text-3xl md:text-4xl font-bold text-white mb-4 leading-tight","children":"SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests"}],["$","div",null,{"className":"flex flex-wrap items-center gap-x-4 gap-y-1 text-primary-100 text-sm","children":[["$","span",null,{"children":"Punya Syon Pandey, Hai Son Le, Devansh Bhardwaj, Rada Mihalcea, Zhijing Jin"}],[["$","span",null,{"className":"hidden sm:inline","children":"·"}],["$","span",null,{"children":"October 9, 2025"}]]]}]]}]}],["$","div",null,{"className":"border-b border-gray-200 bg-gray-50","children":["$","div",null,{"className":"max-w-4xl mx-auto px-6 py-3 flex flex-wrap items-center gap-3","children":["$","a",null,{"href":"https://arxiv.org/abs/2510.04891","target":"_blank","rel":"noopener noreferrer","className":"inline-flex items-center gap-1.5 px-4 py-1.5 text-sm font-medium rounded-lg bg-primary-700 text-white hover:bg-primary-800 transition-colors","children":[["$","svg",null,{"className":"w-4 h-4","fill":"none","stroke":"currentColor","viewBox":"0 0 24 24","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253"}]}],"Read the paper on arXiv"]}]}]}],["$","article",null,{"className":"max-w-3xl mx-auto px-6 py-12 lg:py-16","children":["$","div",null,{"className":"prose prose-base prose-gray prose-headings:text-gray-900 prose-a:text-primary-700 prose-a:no-underline hover:prose-a:underline prose-code:bg-gray-100 prose-code:px-1.5 prose-code:py-0.5 prose-code:rounded prose-code:text-sm prose-pre:bg-gray-900 prose-pre:text-gray-100 [&_pre_code]:bg-transparent [&_pre_code]:p-0 prose-img:rounded-xl","children":[["$","h2","h2-0",{"children":"Overview"}],"\n",["$","p","p-0",{"children":["Motivated by the increasing safety concerns of LLMs, particularly with LLMs used in political contexts, we propose ",["$","strong","strong-0",{"children":"SocialHarmBench"}],", the first comprehensive benchmark to evaluate the vulnerability of LLMs to socially harmful goals with 78,836 prompts from 47 democratic countries collected from 16 genres and 11 domains."]}],"\n",["$","h2","h2-1",{"children":"The Challenge"}],"\n",["$","p","p-1",{"children":"As LLMs are increasingly deployed in sensitive sociopolitical contexts, existing safety benchmarks overlook evaluating risks like assisting surveillance, political manipulation, and generating disinformation. There is a critical gap in understanding how these models respond to socially harmful prompts across different countries and cultural contexts."}],"\n",["$","h2","h2-2",{"children":"Methodology"}],"\n",["$","p","p-2",{"children":"These prompts were carefully collected and human-verified by LLM safety experts and political experts. To test the model's vulnerability in these prompts, we leverage red-teaming techniques and two evaluation settings."}],"\n","$L4","\n","$L5","\n","$L6","\n","$L7","\n","$L8"]}]}]]}],"$L9"]}],["$La"],"$Lb"]}],"loading":null,"isPartial":false}
4:["$","h2","h2-3",{"children":"Key Findings"}]
5:["$","p","p-3",{"children":"From our experiments on 15 cutting-edge LLMs, many safety risks are uncovered:"}]
6:["$","ul","ul-0",{"children":["\n",["$","li","li-0",{"children":"The state-of-the-art GPT-4.1 refuses to follow harmful requests more frequently than the rest (84.93%), but is sometimes more resistant to safety abridged priming."}],"\n",["$","li","li-1",{"children":"Llama-3.1-Instruct and Qwen2.5-Instruct are identified as the most vulnerable, when focusing on subgroups like 100 different sensitive groups to detect safety risks of online discrimination."}],"\n"]}]
7:["$","h2","h2-4",{"children":"Impact"}]
8:["$","p","p-4",{"children":"We plan to release the benchmark to facilitate the study of safety risks pertaining to social and political domains in LLMs, providing the research community with a practical tool for auditing and improving the sociopolitical safety of generative AI systems."}]
9:["$","footer",null,{"className":"bg-gray-900 text-white","children":[["$","div",null,{"className":"max-w-6xl mx-auto px-6 py-12","children":["$","div",null,{"className":"grid md:grid-cols-4 gap-8","children":[["$","div",null,{"className":"md:col-span-2","children":[["$","$Lc",null,{"src":"/images/logo.png","alt":"EuroSafeAI","width":120,"height":50,"className":"h-8 w-auto object-contain brightness-0 invert mb-4"}],["$","p",null,{"className":"text-gray-400 text-sm leading-relaxed mb-4 max-w-sm","children":"EuroSafeAI is a nonprofit research organization registered under Swiss law, dedicated to advancing AI safety and security. We have a deep collaboration with the University of Toronto."}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-white mb-4","children":"Quick Links"}],["$","ul",null,{"className":"space-y-2","children":[["$","li",null,{"children":["$","$L3",null,{"href":"/","className":"text-gray-400 hover:text-white text-sm transition-colors","children":"Home"}]}],["$","li",null,{"children":["$","$L3",null,{"href":"/research","className":"text-gray-400 hover:text-white text-sm transition-colors","children":"Research"}]}],["$","li",null,{"children":["$","$L3",null,{"href":"/team","className":"text-gray-400 hover:text-white text-sm transition-colors","children":"Our Team"}]}],["$","li",null,{"children":["$","$L3",null,{"href":"/careers","className":"text-gray-400 hover:text-white text-sm transition-colors","children":"Careers"}]}]]}]]}],["$","div",null,{"children":[["$","h4",null,{"className":"font-semibold text-white mb-4","children":"Contact"}],["$","ul",null,{"className":"space-y-2","children":[["$","li",null,{"children":["$","a",null,{"href":"mailto:eurosafeai.zurich@gmail.com","className":"text-gray-400 hover:text-white text-sm transition-colors flex items-center gap-2","children":[["$","svg",null,{"className":"w-4 h-4 flex-shrink-0","fill":"none","stroke":"currentColor","viewBox":"0 0 24 24","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M3 8l7.89 5.26a2 2 0 002.22 0L21 8M5 19h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z"}]}],["$","span",null,{"children":"eurosafeai.zurich@gmail.com"}]]}]}],["$","li",null,{"className":"text-gray-400 text-sm flex items-center gap-2","children":[["$","svg",null,{"className":"w-4 h-4 flex-shrink-0","fill":"none","stroke":"currentColor","viewBox":"0 0 24 24","children":[["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M17.657 16.657L13.414 20.9a1.998 1.998 0 01-2.827 0l-4.244-4.243a8 8 0 1111.314 0z"}],["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","strokeWidth":2,"d":"M15 11a3 3 0 11-6 0 3 3 0 016 0z"}]]}],["$","span",null,{"children":"Zurich, Switzerland"}]]}]]}]]}]]}]}],["$","div",null,{"className":"border-t border-gray-800","children":["$","div",null,{"className":"max-w-6xl mx-auto px-6 py-4 flex flex-col md:flex-row justify-between items-center gap-2","children":[["$","p",null,{"className":"text-gray-500 text-sm","suppressHydrationWarning":true,"children":["© ",2026," EuroSafeAI. All rights reserved."]}],["$","p",null,{"className":"text-gray-500 text-sm","children":"Swiss nonprofit registered under Swiss Law"}]]}]}]]}]
a:["$","script","script-0",{"src":"/_next/static/chunks/00e9ab075e5969cf.js","async":true}]
b:["$","$Ld",null,{"children":["$","$e",null,{"name":"Next.MetadataOutlet","children":"$@f"}]}]
f:null
